<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kernel on A Developer&#39;s Note</title>
    <link>https://seokbeomKim.github.io/categories/kernel/</link>
    <description>Recent content in kernel on A Developer&#39;s Note</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Apr 2020 06:04:17 +0900</lastBuildDate>
    
	<atom:link href="https://seokbeomKim.github.io/categories/kernel/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Vmlinux</title>
      <link>https://seokbeomKim.github.io/posts/vmlinux/</link>
      <pubDate>Tue, 21 Apr 2020 06:04:17 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/vmlinux/</guid>
      <description>커널 패닉 정보를 바탕으로 패닉이 정확히 어디서 발생했는지를 알아내기 위해 vmlinux 파일을 이용하는 방법을 알게 되었다. addr2line 명령어를 이용하여 PC 또는 LR에 들어있던 주소를 이용하여 실행된 명령어가 코드상으로 어디에 위치했는지를 알아내는 것인데 어떤 이유로 디버깅이 가능한지 궁금했기에 이 포스팅에서는 addr2line을 이용한 커널패닉 분석 방법과 vmlinux에 관련된 파일 종류에 대해 간단히 언급하고자 한다.
커널 패닉 메시지 분석하기 출처로 명시된 페이지에서 기술되어 있듯 아래와 같은 커널 패닉 메시지가 나왔다고 가정했을 때 addr2line 명령어와 vmlinux 파일을 이용해 실행 위치를 알아낼 수 있다.</description>
    </item>
    
    <item>
      <title>가상주소와 페이지 테이블 크기</title>
      <link>https://seokbeomKim.github.io/posts/page-table-entry-and-va-bits/</link>
      <pubDate>Sat, 11 Apr 2020 18:25:16 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/page-table-entry-and-va-bits/</guid>
      <description>각 태스트(유저 레벨에서 프로세스라고 일컫는)에는 각각의 가상주소를 갖는다. 사용되는 가상주소는 메모리 상에서 MMU에 의해 물리 메모리로 접근이 가능한데 이 때 MMU에 &amp;lsquo;어떻게 가상 주소를 맵핑할 것인지&#39;에 대한 정보를 전달해줘야 한다. 이러한 정보는 &amp;lsquo;페이지 테이블&#39;이라는 것으로 표현되어 그 물리주소를 MMU에서 참고하는 레지스터 정보에 저장하게 된다. 포스팅에서 기준으로 삼은 아키텍처는 ARM64이다. ARM64 커널에서는 사용 가능한 페이지의 크기로서 4K, 16K, 64K 등을 사용하고 있고 가상주소 비트 수(VA_BITS)로서 36, 39, 42, 47, 48비트 등을 사용한다.</description>
    </item>
    
    <item>
      <title>Futex</title>
      <link>https://seokbeomKim.github.io/posts/futex/</link>
      <pubDate>Thu, 02 Apr 2020 01:45:50 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/futex/</guid>
      <description>Futex (Fast Userspace Mutexes) futex는 전통적인 UNIX 커널에서 사용되고 있는 sleep/wakup과 매우 비슷한 동기 기구를 userland에 대해 제공한다. 주로 NPTL(Native POSIX Thread Library) 등의 라이브러리의 구현에 사용되기 때문에 애플리케이션으로부터 직접 이용하는 경우는 별로 없다고 생각되지만 POSIX Thread는 Java 스레드의 구현 등에도 이용되고 있어 동기 처리를 많이 이용하는 애플리케이션에는 이익이 있을 것이다. futex 시스템 콜의 주된 기능은 FUTEX_WAIT와 FUTEX_WAKE이다.
pthread_mutex_lock  아토믹 명령을 사용하여 lock을 시도 1에서 lock이 성공되면 종료 FUTEX_WAIT를 사용하여 pthread_mutex_t의 주소 상에서 슬립한다 시동 후, 1로 돌아간다  pthread_mutex_unlock  아토믹 명령을 사용해 unlock 처리를 실시 1의 결과, 슬립하고 있는 스레드가 있다면 FUTEX_WAKE를 사용하여 wakeup한다.</description>
    </item>
    
    <item>
      <title>Do While</title>
      <link>https://seokbeomKim.github.io/posts/do-while/</link>
      <pubDate>Wed, 01 Apr 2020 23:55:32 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/do-while/</guid>
      <description>개요 커널 매크로에 do { .. } while(0) 구문을 사용하는 것을 보게 되었다. 사내 코드에서도 이러한 구문들이 많이 보였는데 처음에는 의미없이 이상하게 짜여진 코드라고 생각했다. 그런데 그런 구문에도 의미가 있었다. https://kernelnewbies.org/FAQ/DoWhile0 링크를 보면 이러한 구문을 만든 이유가 기술되어 있다. 이러한 구문에 대한 이유는 아래와 같다.
 빈 구문(empty statement)는 컴파일러가 경고를 낸다. 지역 변수를 선언할 수 있는 구역을 만들어준다. 조건문을 포함한 코드에서 복잡한 형태의 매크로를 사용할 수 있도록 해준다.  조건문을 포함한 코드에서의 매크로 사용 #define FOO(x) \ printf(&amp;#34;arg is %s\n&amp;#34;, x); \ do_something_useful(x); 이 때 위처럼 정의한 매크로를 조건문과 함께 사용하게 된다면 아래와 같이 사용하게 된다.</description>
    </item>
    
    <item>
      <title>poll() 그리고 poll_wait()</title>
      <link>https://seokbeomKim.github.io/posts/poll-and-poll_wait/</link>
      <pubDate>Tue, 10 Mar 2020 23:52:01 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/poll-and-poll_wait/</guid>
      <description>개요 업무 중에 카메라 드라이버에 관련된 이슈를 보다가 poll()과 poll_wait()이 지속적으로 사용되는 것을 볼 수 있었다. 이슈에 관련된 커널이 다소 오래되었기에 살펴보아야 하는 드라이버 코드도 레거시에 가까웠지만 poll을 이용하여 디바이스 드라이버의 인터럽트를 처리하는 것으로 확인하여 관련 내용을 정리하고자 한다.
리눅스 커널에서 제공하는 poll 함수에 대해서 원문으로 작성된 여러 출처들이 있었지만 아무래도 처음부터 원문을 읽고 이해하기에는 다소 어려움이 있었다. falinux에 작성된 문서를 기반으로 아래와 같이 개념적인 내용만 재정리하는 방식으로 포스팅을 작성하려 한다.</description>
    </item>
    
    <item>
      <title>MICOM과 MPU</title>
      <link>https://seokbeomKim.github.io/posts/micom-vs-mpu/</link>
      <pubDate>Sun, 08 Mar 2020 23:30:44 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/micom-vs-mpu/</guid>
      <description>개요 카메라 관련 업무로 ARM Cortex A7 Single 모델을 주로 사용하지만 A53, MICOM 과의 인터럽트 충돌 문제가 일어날 때가 있다. UART 부트 및 LVDS 채널 변경, 더 나아가 카메라 센서의 초기화까지 마이컴에서 담당하게 되는 시나리오가 있어 마이컴이 정확히 어떤 것인지 한번은 짚고 넘어가야 했다.
마침 한 블로그에 마이컴에 대해 간략하게 정리가 되어 있고 연관된 토픽 별로 정리해놓은 페이지가 있어 필요한 부분만 간추려 본 페이지로 정리하기로 한다.
본문 출처 내용 그대로 uC는 MicroController, uP는 MicroProcessor, &amp;ldquo;Adv&amp;quot;는 Advanced Topic의 줄임말로서 사용한다.</description>
    </item>
    
    <item>
      <title>IOCTL과 인터럽트</title>
      <link>https://seokbeomKim.github.io/posts/ioctl-and-interrupt/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:10 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/ioctl-and-interrupt/</guid>
      <description>개요 디바이스 드라이버와 인터럽트 핸들러 간의 동기화 때문에 머리가 아팠다. 현재도 해결하지 못하고 있는 이슈가 있어 계속해서 찾아보고 있는 와중에 StackOverflow에서 재미있는 질문을 찾았다.
 [[https://stackoverflow.com/questions/60088342/does-context-switching-occurs-when-ioctl-is-issued-from-user-space-while-kernel]]  문제 자체는 커널 모듈 안에 있는 critical section에서 스핀락을 사용하지 않을 때 irq나 softirq를 비활성화하지 않고도 데드락에 빠지지 않고 정상적으로 동작이 가능한가에 대한 질문이다. 질문에 대한 답변부터 살펴보면,
  IRQ/SoftIRQ는 시스템 콜과 아무런 영향이 없다. 단지 인터럽트 컨텍스트 안에서 사용되는 데이터 구조들을 보호하기 위해 IRQ와 softIRQ를 비활성화하는 것 뿐이다.</description>
    </item>
    
    <item>
      <title>리눅스에서의 버퍼링 방식</title>
      <link>https://seokbeomKim.github.io/posts/buffering-in-linux/</link>
      <pubDate>Sat, 29 Feb 2020 23:34:30 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/buffering-in-linux/</guid>
      <description>리눅스에서의 버퍼링 정책 리눅스에서는 파일 입출력을 할 때 물리적인 파일에 조회 및 기록의 횟수를 최소화하여 성능을 높이기 위해 버퍼링 정책을 사용하고 있다.
만약 write 호출로 데이터를 쓰기 명령을 전달하면 해당 파일 작업을 위한 버퍼에 기록을 해 두었다가 정책에 따라 특정 시점에 물리적인 파일에 기록을 수행한다. 리눅스에서 제공하는 버퍼링 정책에는 버퍼가 꽉 차면 물리적인 파일에 기록하는 Full Buffering과 꽉 차거나 개행문자가 오면 처리하는 Line Buffering, 버퍼를 사용하는 않는 Null Buffering 정책을 제공하고 있다.</description>
    </item>
    
    <item>
      <title>ioctl()에 전달되는 cmd 관련 매크로 함수</title>
      <link>https://seokbeomKim.github.io/posts/ioctl_cmd_macro/</link>
      <pubDate>Thu, 27 Feb 2020 00:23:10 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/ioctl_cmd_macro/</guid>
      <description>드라이버 코드 내에서 ioctl commands 를 정의하기 위해 단순 integer를 사용하는 게 아니라 매크로를 통해 생성을 하고 있었다. 이에 관련 내용을 포스팅과 함께 정리하고자 한다.
저수준 파일 입출력 함수인 ioctl()을 디바이스 파일에 적용시키면 디바이스 파일에 연결된 디바이스 드라이버의 file_operation 구조체의 ioctl 필드에 선언된 함수가 호출된다. ioctl 함수는 디바이스마다 고유하게 선언하여 사용하는데, 일반적으로 하드에워의 제어나 상태를 얻기 위해 사용한다.
cmd 구성 디바이스 드라이버의 ioctl() 함수에 전달되는 매개변수 cmd는 응용 프로그램이 디바이스 드라이버에게 요구한 처리를 구별하기 위한 구별값이다.</description>
    </item>
    
    <item>
      <title>Identity Mapping</title>
      <link>https://seokbeomKim.github.io/posts/idmap/</link>
      <pubDate>Mon, 24 Feb 2020 23:01:54 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/idmap/</guid>
      <description>ARM64 페이징을 공부하다보니 idmap (Identity Mapping)이라는 용어가 등장했다. 페이지 테이블이 완전하게 준비가 되지 않았을 때 임시로 사용하는 매핑 방법 중의 하나인데 오늘을 여기에 대해서 정리하고자 한다.
 idmap이 무엇이고 왜 필요한가? idmap 을 사용하는 코드는 어떤 것이 있는가? ARM 리눅스 커널에서는 어떻게 활용하고 있는가?  idmap (Identity Mapping) 가상주소와 물리주소가 매핑되는 방식 중의 한 가지다. 리눅스 커널에서 사용하는 주소 매핑 방식을 아래와 같이 3가지로 구분할 수 있다.
linear 영역 가상주소 + offset = 물리주소 와 같이 주소 변환이 가능한 방식이다.</description>
    </item>
    
    <item>
      <title>WARN_ON, BUG_ON 매크로</title>
      <link>https://seokbeomKim.github.io/posts/warn_on-and-bug_on/</link>
      <pubDate>Fri, 21 Feb 2020 00:12:34 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/warn_on-and-bug_on/</guid>
      <description>개요 업무 중에 예전 SDK에서 커널 패닉이 일어나는 것을 보고 관련 코드를 살펴보니, BUG_ON 매크로 사용에 의한 것으로 파악했다. 커널 패닉을 일으킬 정도로 크리티컬은 아니었기에 해당 매크로를 WARN_ON으로 변경하였다. 변경 이후에 커널 패닉은 일어나지 않았지만 커널 메시지로 보여주는 내용이 조금 달랐다.
이 글에서는 BUG_ON, WARN_ON 등 커널에서 제공하는 assertion에 해당하는 매크로가 어떤 것들이 있는지 살펴보고 어떤 경우에 사용해야 하는지에 대해 간략히 정리하고자 한다. 이 외에 커널에서는 dump_stack(), save_stack_trace(), dump_trace(), backtrace() 등의 콜 스택 출력 방법을 제공한다.</description>
    </item>
    
    <item>
      <title>Likely and Unlikely</title>
      <link>https://seokbeomKim.github.io/posts/likely-and-unlikely/</link>
      <pubDate>Thu, 13 Feb 2020 23:27:51 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/likely-and-unlikely/</guid>
      <description>개요 예전에 관리하던 블로그에서 커널에서 사용하는 likely와 unlikely 에 대해서 정리한 포스팅이 있었다. 하지만 시간이 지나 커널 분석 책을 다시 보며 likely, unlikely를 보니 다시 헷갈리기 시작했다.
회사 업무에서 실행 시간을 줄이는 데에 중요도를 두고 있지만 그 방법에 대해서는 아직 다루지 못하고 있다. 솔루션이 안정화되고 전체적인 업무 내용이 파악되면 본 내용을 정리하면서 실행 시간을 감소할 방법으로 prediction을 이용하는 것을 건의해보고 진행해볼 수 있을 것 같다.
likely(), unlikely() 함수의 이름 그대로, 자주 일어날 듯하거나 자주 일어나지 않을 듯한 것을 위한 매크로이다.</description>
    </item>
    
    <item>
      <title>ftrace 이용한 커널 디버깅</title>
      <link>https://seokbeomKim.github.io/posts/ftrace/</link>
      <pubDate>Thu, 06 Feb 2020 23:43:34 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/ftrace/</guid>
      <description>개요 커널 디버깅을 위해 procfs, sysfs, 레지스터 덤프 등의 단순 정보를 제외한 다른 방법은 없을까? 업무에서 문제 원인 파악을 위해서는 디버깅이 중요한데 커널에서는 사용할 수 있는 디버깅 툴이 제한적이다. 또한, 팀 내에서도 로그나 레지스터 외에 별다른 디버깅 도구를 사용하는 것 같지 않아, 다른 방법이 있는지 찾아보던 중 익숙한 이름의 ftrace가 있다는 것을 알게 됐다.
예전에 젠투 리눅스를 사용할 무렵, menuconfig에서 커널 해킹이라는 흥미로운 메뉴에서 알 수 없는 tracer라는 메뉴로만 본 것으로 이해하지 직접적으로 사용한 적은 없었는데, 실제 사용해보니 생각보다 많은 옵션, 정보들을 보여주었다.</description>
    </item>
    
    <item>
      <title>ARM64에서의 커널 메모리 맵</title>
      <link>https://seokbeomKim.github.io/posts/arm64_kernel_memory_map/</link>
      <pubDate>Sat, 01 Feb 2020 23:27:45 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/arm64_kernel_memory_map/</guid>
      <description>ARM64에서의 커널 메모리 맵 &amp;lt;코드로 알아보는 ARM 리눅스 커널&amp;gt; 에서의 &amp;ldquo;페이징과 매핑&amp;quot;이라는 챕터를 읽으면서 커널 메모리 맵에 대한 간략한 설명을 포스팅으로 정리하고자 한다. 물리 메모리와 가상 메모리 주소간의 매핑을 위해 사용하는 테이블을 매핑 테이블이라고 하며, 본 포스팅에서는 기본적인 개념인 가상 주소 공간과 ARM64에서의 커널 메모리 맵 구성을 정리한다.
ARM64 커널에서는 64비트 가상 주소의 시작 부분과 끝부분의 영역을 사용한다. 이 때, 가상 주소 기준으로 각 끝 영역을 사용한다는 점에 유의해야 한다.</description>
    </item>
    
    <item>
      <title>GPIO Mapping</title>
      <link>https://seokbeomKim.github.io/posts/gpio_mapping/</link>
      <pubDate>Fri, 31 Jan 2020 23:48:06 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/gpio_mapping/</guid>
      <description>GPIO 맵핑하기 오늘은 gpio 맵핑을 위해 디바이스 트리를 이용하였지만 정상적으로 설정되지 않는 문제가 있었다. SoC에서 GPIO Enable 에 대한 것이 문제일 것이라 예상되지만, GPIO 맵핑하는 방법으로 디바이스 트리를 이용하는 것 외에 어떤 대안이 있는지 알아보고자 정리하고자 한다.
GPIO 데이터를 맵핑하여 사용할 수 있는 방법은 아래와 같이 세 가지 방법이 있다.
 디바이스 트리 이용 (최근 트렌드) Legacy Board &amp;amp; Machine Specific Code에서 플랫폼 데이터로 정의   (출처에 따르면) GPIO 맵핑을 플랫폼 데이터에 등록하여 사용하는 경우는 많지 않고 단순하게 핀 번호로 사용하는 경우가 대부분이었다고 한다.</description>
    </item>
    
    <item>
      <title>/dev/mem vs. /dev/kmem</title>
      <link>https://seokbeomKim.github.io/posts/mem_vs_kmem/</link>
      <pubDate>Wed, 29 Jan 2020 23:30:44 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/mem_vs_kmem/</guid>
      <description>개요 업무에서 사용하는 디버깅 툴은 특정 레지스터 정보를 보기 위해, 메모리 상에 매핑되어 있는 주소에 접근하여 해당 레지스터의 값을 읽어오는 방식을 이용한다. 이 때, /dev/mem 디바이스 노드가 반드시 있어야 한다고 들었기에 Kconfig에서 관련 설정 플래그를 찾던 중 kmem 이라는 것도 있다는 것을 알게 되었다. 문득 이 둘의 차이점과 공식적(?)인 디버깅 툴이 어떤 것이 있는지 알아보고자 한다.
/dev/mem vs. /dev/kmem 이 둘의 차이점은 출처에 따르면 아래와 같이 나와있다.
 /dev/mem is a device file that directly represents physical memory, so an open(/dev/mem)/seek(1000)/read(10) system call combination ends up reading 10 bytes from RAM address 1000.</description>
    </item>
    
    <item>
      <title>Kobject</title>
      <link>https://seokbeomKim.github.io/posts/kobject/</link>
      <pubDate>Tue, 28 Jan 2020 22:25:50 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/kobject/</guid>
      <description>kobjects, ktypes, ksets 디바이스 트리를 살펴보다 kobject 에 대한 내용이 언급되기 시작했다. 단순한 객체가 아니라 특수한 목적으로 사용될 것이라 예상되어 관련 내용을 찾아보았다.
61 struct kobject { 62 const char *name; 63 struct list_head entry; 64 struct kobject *parent; 65 struct kset *kset; 66 struct kobj_type *ktype; 67 struct kernfs_node *sd; 68 struct kref kref; 69 #ifdef CONFIG_DEBUG_KOBJECT_RELEASE 70 struct delayed_work release; 71 #endif 72 unsigned int state_initialized:1; 73 unsigned int state_in_sysfs:1; 74 unsigned int state_add_uevent_sent:1; 75 unsigned int state_remove_uevent_sent:1; 76 unsigned int uevent_suppress:1; 77 }; 커널 문서(https://www.</description>
    </item>
    
    <item>
      <title>Little Endian vs. Big Endian</title>
      <link>https://seokbeomKim.github.io/posts/endian/</link>
      <pubDate>Mon, 27 Jan 2020 22:27:06 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/endian/</guid>
      <description>개요 빅 엔디안과 리틀 엔디안에 관해 업무에서 접할 수 있는 상황과 각각에 해당하는 포인터 연산 예제를 종합적으로 정리하도록 한다.
엔디안(Endianness)은 컴퓨터의 메모리와 같은 1차원 공간에 여러 개의 연속된 대상을 배열하는 방법을 뜻하며, 바이트를 배열하는 방법을 바이트 순서(Byte-order)라고 한다. 엔디안은 보통 큰 단위가 앞에 나오는 빅 엔디안(Big-Endian)과 작은 단위가 앞에 나오는 리틀 엔디안(Little-Endian)으로 나눌 수 있으며, 두 경우에 속하지 않거나 둘 모두 지원하는 것을 미들 엔디안(Middle-Endian)이라 부른다.
 Big-Endian: 최상위 바이트(MSB)부터 차례로 저장하는 방식 (사람이 읽고 쓰는 방식과 비슷함) Little-Endian: 최하위 바이트(LSB)부터 차례로 저장하는 방식  예제 예를 들어, 메모리에 0x12345678을 대입한다고 했을 때, 빅 엔디안과 리틀 엔디안 각각 아래와 같이 저장된다.</description>
    </item>
    
    <item>
      <title>RCU (Read, Copy, Update)</title>
      <link>https://seokbeomKim.github.io/posts/rcu/</link>
      <pubDate>Tue, 04 Jun 2019 17:34:42 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/rcu/</guid>
      <description>1. 들어가기 전에 &amp;hellip; 앞으로 기술하는 내용은 http://jake.dothome.co.kr/rcu/#comment-214230 에서 발췌하여 정리하는 내용이므로 원본 내용 확인을 위해서는 링크에서 직접 보길 권한다. RCU 내용 뿐만 아니라, 리눅스 커널 전반적인 내용에 대해 정말 자세하게 정리가 잘 되어있다.
RCU(Read, Copy, Update)란 리눅스 커널 내에서 주로 읽기 연산만 일어나고 쓰기 연산의 비중은 매우 작은 객체에 주로 쓰이는 동기화 기법이다. Reader-Writer 락과 비슷한 동기화 기법인데, RW 락에 대해 RCU가 가지는 상대적인 강점으로는 읽기 연산이 wait-free(읽기 연산에 대해 Block이 일어나지 않음)이며 그 오버헤드가 극도로 작다는 점 등이 있다.</description>
    </item>
    
    <item>
      <title>Major와 Minor Numbers</title>
      <link>https://seokbeomKim.github.io/posts/major-and-minor-numbers/</link>
      <pubDate>Fri, 31 May 2019 18:37:25 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/major-and-minor-numbers/</guid>
      <description>세마포어를 이용한 모듈 프로그래밍을 하던 중 Major, Minor 라는 개념이 등장하였다. 인터넷으로 찾은 커널 모듈 소스가 구버전 커널을 기준으로 한 까닭에, 커널 코드가 어떻게 변경되어 갔는지 히스토리를 삽질해 볼 수 있는 아주 좋은 기회다.
캐릭터 디바이스는 /dev 디렉토리에서 쉽게 확인할 수 있는데 파일의 속성에서 각 장치에 대한 속성은 맨 앞 문자를 통해 판단할 수 있다. 예를 들어, &amp;lsquo;c&#39;를 포함하고 있다면 캐릭터 디바이스(character devices)를 위한 특수 파일로, &amp;lsquo;b&#39;를 포함하고 있다면 블록 디바이스(block devices)로 식별할 수 있다.</description>
    </item>
    
    <item>
      <title>리눅스 커널 락 종류 (1/5)</title>
      <link>https://seokbeomKim.github.io/posts/locks-in-the-kernel-1/</link>
      <pubDate>Tue, 28 May 2019 17:45:51 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/locks-in-the-kernel-1/</guid>
      <description>&lt;p&gt;리눅스 커널에서 사용되는 락의 종류는 다양하다. 학부 시절, &lt;em&gt;&amp;lsquo;뮤텍스는
세마 포어의 카운트가 1인 락&#39;이라는 말도 안되는 내용으로 학교
선배로부터 배웠던 것이 기억난다.&lt;/em&gt; 락의 종류별로 쓰임새가 있고 장단점이
있는 것인데, 이 문서에는 커널에서 사용하는 락(lock)의 종류와 각각에
대한 사용 예를 기술하고자 한다.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>지피(Jiffies)</title>
      <link>https://seokbeomKim.github.io/posts/jiffies/</link>
      <pubDate>Sun, 26 May 2019 10:38:40 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/jiffies/</guid>
      <description>오랜만에 지피에 대한 포스팅을 다시 작성한다(대학생 때 커널 공부를 한 뒤로 이렇게 별도로 문서를 작성하는 것은 처음인 것 같다). 전역 변수인 jiffies에는 시스템 시작 이후 발생한 진동 횟수(tick)이 저장된다. 시스템 시작 시 커널은 이 값을 0으로 설정하고 타이머 인터럽트가 발생할 때마다 1씩 증가시킨다. 타이머 인터럽트는 초당 HZ회 발생하므로, 초당 지피 수는 HZ가 되며, 이에 따라 시스템 가동 시간은 jiffies / HZ(초)가 된다.
커널은 버그 식별을 위해 jiffies 변수의 오버플로우 현상이 자주 일어나기 위해 jiffies 변수를 0이 아닌 특별한 값으로 초기화하며 실제 jiffies값이 필요한 경우에는 이 차이(offset)값을 빼야 한다.</description>
    </item>
    
    <item>
      <title>태스크릿(Tasklet)</title>
      <link>https://seokbeomKim.github.io/posts/tasklet/</link>
      <pubDate>Sat, 25 May 2019 17:32:26 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/tasklet/</guid>
      <description>커널 모듈 프로그래밍을 연습하던 도중, 태스크릿 예제를 접하게 되었다. 한참 전에 태스크릿이 어떤 것인지 이론으로 접하기는 했으나 직접 사용해본 적은 없었기 때문에 이 문서를 통해 정리하고자 한다.
간단히 말해 tasklet은 스택이나 자체 컨텍스트가 없는 스레드와 같은 것으로 설명하고 있다.
태스크릿(Tasklet)의 특성  태스크릿(tasklet)은 원자성을 가지고 있기 때문에 mutex, semaphore와 같은 동기화 수단을 사용하거나 sleep() 을 사용할 수 없다. 단, spinlock은 가능하다. ISR보다 유연한 컨텍스트(softer context)로 불린다. 때문에 태스크릿의 컨텍스트 도중 하드웨어 인터럽트가 발생하는 것을 허용한다.</description>
    </item>
    
    <item>
      <title>커널 모듈과 드라이버의 차이</title>
      <link>https://seokbeomKim.github.io/posts/kernel-module-and-drivers/</link>
      <pubDate>Thu, 16 May 2019 02:11:40 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/kernel-module-and-drivers/</guid>
      <description>오랜만에 커널 공부를 다시 시작하면서 소스 트리를 다시 살펴보게 되었다. 분명히 예전에도 같은 질문을 가졌겠거니 생각하면서 트리를 보고 난 후의 첫 질문을 정리하고자 한다.
커널 디렉토리 구조는 대략 다음과 같이 구성되며, 그 중 drivers와 modules의 차이점이 이해하기가 어려웠다.
arch/ - 특정 아키텍처에 국한된 코드 include/ - 커널 빌드를 위해 포함하는 include 파일들 init/ - 커널 초기화 코드 mm/ - 메모리 관리 코드 drivers/ - 드라이버 ipc/ - IPC (Inter Process Communication) modules/ - 커널 모듈 fs/ - 파일시스템 kernel/ - 커널 코드 net/ - 네트워킹 코드 lib/ - 커널에서 사용하는 라이브러리 scripts/ - awk, tk와 같은 스크립트들(커널 configure 시에 사용) 구글링을 해보니 역시나 같은 생각을 한 사람이 있었다.</description>
    </item>
    
    <item>
      <title>비선점 스케쥴링(Nonpreemptive Scheduling)</title>
      <link>https://seokbeomKim.github.io/posts/nonpreemptive_scheduling/</link>
      <pubDate>Wed, 15 May 2019 18:44:06 +0900</pubDate>
      
      <guid>https://seokbeomKim.github.io/posts/nonpreemptive_scheduling/</guid>
      <description>비선점 스케쥴링(Non-preemptive Scheduling) 비선점 스케쥴링(Non-preemptive Scheduling)은 프로세스가 자원을 할당받았을 경우 자원을 스스로 반납할 때까지 계속 그 자원을 사용하도록 허용하는 정책이다. 적용할 때는 현재 프로세서를 사용하는 프로세스가 생성되거나 현재 프로세스 작업을 종료할 때 입출력하기 위해 스스로 프로세서를 반납할 때까지 우선 순위가 높은 프로세스의 비선점 정책을 적용하면 프로세스의 종료 시간을 비교적 정확하게 예측할 수 있다.
설명하기 전에 프로세스가 입출력 중심의 대화형 프로세스인지, 프로세서 실행 중심의 프로세스인지를 먼저 구분하는 것이 스케쥴링 정책을 적용하는 단계의 첫 번째이다.</description>
    </item>
    
  </channel>
</rss>